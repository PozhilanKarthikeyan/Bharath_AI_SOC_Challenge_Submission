{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U6irBrux_fg"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oCjybLK4FVMR",
        "outputId": "4ba34a6c-8b8c-4159-c587-873cd1b9f9b1"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WzJBUC3yKQm"
      },
      "source": [
        " # **Dataset Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wXHN0GwKoKn",
        "outputId": "0356c514-afa4-4ae2-9310-e09feb078d31"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/content/sar_project'\n",
        "os.makedirs(f'{BASE_DIR}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{BASE_DIR}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{BASE_DIR}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{BASE_DIR}/labels/val', exist_ok=True)\n",
        "\n",
        "# Unzip images and labels\n",
        "\n",
        "!unzip -q /content/drive/MyDrive/images_ship_detection.zip -d /content/temp_images\n",
        "!unzip -q /content/drive/MyDrive/labels_ship_detection.zip -d /content/temp_labels\n",
        "\n",
        "image_files = sorted([f for f in os.listdir('/content/temp_images/images') if f.endswith('.jpg')])\n",
        "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
        "\n",
        "def move_files(files, split):\n",
        "    for f in files:\n",
        "        shutil.move(f'/content/temp_images/images/{f}', f'{BASE_DIR}/images/{split}/{f}')\n",
        "        label_name = f.replace('.jpg', '.txt')\n",
        "        shutil.move(f'/content/temp_labels/labels/{label_name}', f'{BASE_DIR}/labels/{split}/{label_name}')\n",
        "\n",
        "move_files(train_files, 'train')\n",
        "move_files(val_files, 'val')\n",
        "\n",
        "print(f\"Dataset ready: {len(train_files)} training images, {len(val_files)} validation images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12c8YJAvKyii"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "config = {\n",
        "    'path': BASE_DIR,\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'nc': 1,\n",
        "    'names': ['ship']\n",
        "}\n",
        "\n",
        "with open(f'{BASE_DIR}/sar_data.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuxCbup6ydeG"
      },
      "source": [
        "# **YOLO Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EzIrtw1bK1VP",
        "outputId": "6a4cd689-c4af-4b8d-b89d-885b49ce18c4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/YOLO26_SAR_Project'\n",
        "os.makedirs(GOOGLE_DRIVE_PATH, exist_ok=True)\n",
        "\n",
        "checkpoint_path = os.path.join(GOOGLE_DRIVE_PATH, 'ship_detection/weights/last.pt')\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"--- Found existing checkpoint at {checkpoint_path}. Resuming... ---\")\n",
        "    model = YOLO(checkpoint_path)\n",
        "    results = model.train(resume=True)\n",
        "else:\n",
        "    print(\"--- No checkpoint found. Starting fresh training... ---\")\n",
        "    model = YOLO('yolo26n.pt')\n",
        "    results = model.train(\n",
        "        data=f'{BASE_DIR}/sar_data.yaml',\n",
        "        epochs=100,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        project=GOOGLE_DRIVE_PATH,\n",
        "        name='ship_detection',\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "best_model_path = os.path.join(GOOGLE_DRIVE_PATH, 'ship_detection/weights/best.pt')\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# Extracting the state_dict\n",
        "torch.save(best_model.model.state_dict(), f'{GOOGLE_DRIVE_PATH}/yolo26n_sar_state_dict.pth')\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"DONE! Final weights saved to Drive:\")\n",
        "print(f\"1. Ultralytics format: {best_model_path}\")\n",
        "print(f\"2. Raw state_dict: {GOOGLE_DRIVE_PATH}/yolo26n_sar_state_dict.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b75bFNO3ylUV"
      },
      "source": [
        "# **Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "C341R8fJsqsQ",
        "outputId": "8177a30a-c996-4f59-bad7-f8f671fbaeeb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import math\n",
        "\n",
        "# 1. Load the Best Model\n",
        "best_model_path = os.path.join(GOOGLE_DRIVE_PATH, 'ship_detection/weights/best.pt')\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "# 2. Get 50 Images from Validation Set\n",
        "val_images = glob.glob(f'{BASE_DIR}/images/val/*.jpg')[:50] # Limit to 50\n",
        "print(f\"Running inference on {len(val_images)} images...\")\n",
        "\n",
        "# 3. Run Batch Prediction\n",
        "results = model.predict(source=val_images, conf=0.25, save=False, verbose=False)\n",
        "\n",
        "# 4. Visualization Config (Grid of 5 columns x 10 rows)\n",
        "cols = 5\n",
        "rows = math.ceil(len(val_images) / cols)\n",
        "plt.figure(figsize=(20, 4 * rows)) # Adjust height based on rows\n",
        "\n",
        "for i, r in enumerate(results):\n",
        "    # Plot the bounding boxes on the image\n",
        "    img_plotted = r.plot()\n",
        "\n",
        "    # Convert BGR (OpenCV) to RGB (Matplotlib)\n",
        "    img_rgb = cv2.cvtColor(img_plotted, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create Subplot\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Img {i+1}\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY5QhG4Fzb1r"
      },
      "source": [
        "# **ONNX Conversion FP32**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lZZmSfbPK4yC",
        "outputId": "a0ddf41e-fe04-4c8e-c684-f86ba68b16b1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Path to the BEST weights in your Drive\n",
        "BEST_MODEL_DRIVE = os.path.join(GOOGLE_DRIVE_PATH, 'ship_detection/weights/best.pt')\n",
        "\n",
        "if os.path.exists(BEST_MODEL_DRIVE):\n",
        "    model = YOLO(BEST_MODEL_DRIVE)\n",
        "\n",
        "    model.export(\n",
        "        format='onnx',\n",
        "        simplify=True,\n",
        "        data=f'{BASE_DIR}/sar_data.yaml',\n",
        "        imgsz=640\n",
        "    )\n",
        "\n",
        "    # Ultralytics saves the export in the same folder as the weights\n",
        "    exported_onnx_path = BEST_MODEL_DRIVE.replace('.pt', '.onnx')\n",
        "\n",
        "    DEPLOY_FOLDER = os.path.join(GOOGLE_DRIVE_PATH, 'ONNX_PTH_Files')\n",
        "    os.makedirs(DEPLOY_FOLDER, exist_ok=True)\n",
        "\n",
        "    # Move the ONNX to your deployment folder\n",
        "    if os.path.exists(exported_onnx_path):\n",
        "        shutil.copy(exported_onnx_path, os.path.join(DEPLOY_FOLDER, 'yolo26n_sar_fp32.onnx'))\n",
        "\n",
        "    # Copy the .pth state_dict we created earlier\n",
        "    pth_source = f'{GOOGLE_DRIVE_PATH}/yolo26n_sar_state_dict.pth'\n",
        "    if os.path.exists(pth_source):\n",
        "        shutil.copy(pth_source, os.path.join(DEPLOY_FOLDER, 'yolo26n_sar_state_dict.pth'))\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"--- SUCCESS ---\")\n",
        "    print(f\"Deployment files are ready in: {DEPLOY_FOLDER}\")\n",
        "else:\n",
        "    print(\"Error: Best weights not found in Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bXg17UvTuh5X",
        "outputId": "600d7755-ef10-48aa-a2f4-f510a2677c18"
      },
      "outputs": [],
      "source": [
        "# Install the quantization tool\n",
        "!pip install -q onnxruntime onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHwa-jadzh7U"
      },
      "source": [
        "# **Quantization (INT8) and ONNX Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QcF9Crroufo5",
        "outputId": "85f6b47d-c5c9-4eb6-f318-1aa2feb3c9fa"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Export as Standard FP32 ONNX first (Clean Export)\n",
        "print(\"--- Step 1: Exporting Standard FP32 ONNX ---\")\n",
        "model.export(\n",
        "    format='onnx',\n",
        "    simplify=True,\n",
        "    data=f'{BASE_DIR}/sar_data.yaml',\n",
        "    imgsz=640\n",
        ")\n",
        "\n",
        "# Define paths\n",
        "fp32_path = best_model_path.replace('.pt', '.onnx')\n",
        "int8_path = best_model_path.replace('.pt', '_int8_quantized.onnx')\n",
        "\n",
        "# 2. Perform Manual INT8 Quantization\n",
        "print(f\"\\n--- Step 2: Quantizing {fp32_path} to INT8 ---\")\n",
        "\n",
        "if os.path.exists(fp32_path):\n",
        "    quantize_dynamic(\n",
        "        model_input=fp32_path,\n",
        "        model_output=int8_path,\n",
        "        weight_type=QuantType.QUInt8 # Quantize weights to Unsigned INT8\n",
        "    )\n",
        "    print(\"Quantization Complete!\")\n",
        "\n",
        "    # 3. Move to Deployment Folder\n",
        "    DEPLOY_FOLDER = os.path.join(GOOGLE_DRIVE_PATH, 'ONNX_PTH_Files')\n",
        "    os.makedirs(DEPLOY_FOLDER, exist_ok=True)\n",
        "\n",
        "    final_dest = os.path.join(DEPLOY_FOLDER, 'yolo26n_sar_int8.onnx')\n",
        "    shutil.copy(int8_path, final_dest)\n",
        "\n",
        "    # Also copy the FP32 version\n",
        "    shutil.copy(fp32_path, os.path.join(DEPLOY_FOLDER, 'yolo26n_sar_fp32.onnx'))\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"SUCCESS: INT8 Model saved at: {final_dest}\")\n",
        "    print(f\"Size Check: {os.path.getsize(fp32_path)/1024/1024:.2f} MB (FP32) -> {os.path.getsize(int8_path)/1024/1024:.2f} MB (INT8)\")\n",
        "else:\n",
        "    print(\"Error: FP32 Export failed. Check previous steps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBD69Tik0WqQ"
      },
      "source": [
        "# **Quantization Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9usAUIcmP-da",
        "outputId": "0e4e2c73-204d-4024-8ce4-8fedf6ee9dbe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "fp32_path = os.path.join(GOOGLE_DRIVE_PATH, 'ship_detection/weights/best.pt')\n",
        "int8_path = os.path.join(GOOGLE_DRIVE_PATH, 'ONNX_PTH_Files/yolo26n_sar_int8.onnx')\n",
        "\n",
        "print(f\"Analyzing Models:\\n1. FP32: {fp32_path}\\n2. INT8: {int8_path}\\n\")\n",
        "\n",
        "# --- MODEL SIZE CHECK ---\n",
        "size_fp32 = os.path.getsize(fp32_path) / (1024 * 1024) # MB\n",
        "size_int8 = os.path.getsize(int8_path) / (1024 * 1024) # MB\n",
        "size_reduction = (1 - (size_int8 / size_fp32)) * 100\n",
        "\n",
        "# --- VALIDATION RUNS ---\n",
        "# Load FP32 (Original PyTorch)\n",
        "print(\"-\" * 40)\n",
        "print(\"Running FP32 Validation (Original)...\")\n",
        "model_fp32 = YOLO(fp32_path)\n",
        "metrics_fp32 = model_fp32.val(data=f'{BASE_DIR}/sar_data.yaml', imgsz=640, verbose=False)\n",
        "\n",
        "# Load INT8 (Quantized ONNX)\n",
        "print(\"-\" * 40)\n",
        "print(\"Running INT8 Validation (Quantized)...\")\n",
        "model_int8 = YOLO(int8_path, task='detect')\n",
        "metrics_int8 = model_int8.val(data=f'{BASE_DIR}/sar_data.yaml', imgsz=640, verbose=False)\n",
        "\n",
        "# --- 3. METRIC EXTRACTION ---\n",
        "def get_loss(metrics):\n",
        "    try:\n",
        "        return metrics.loss if metrics.loss else [0, 0, 0]\n",
        "    except:\n",
        "        return [0, 0, 0]\n",
        "\n",
        "loss_fp32 = get_loss(metrics_fp32)\n",
        "loss_int8 = get_loss(metrics_int8) # [0,0,0] for ONNX\n",
        "\n",
        "# Speed\n",
        "speed_fp32 = metrics_fp32.speed['inference']\n",
        "speed_int8 = metrics_int8.speed['inference']\n",
        "\n",
        "# --- FINAL COMPARISON REPORT ---\n",
        "results = {\n",
        "    'Metric': ['Model Size (MB)', 'mAP@50', 'mAP@50-95', 'Inference Time (ms)', 'Box Loss', 'Cls Loss'],\n",
        "    'FP32 (Original)': [\n",
        "        f\"{size_fp32:.2f}\",\n",
        "        f\"{metrics_fp32.box.map50:.4f}\",\n",
        "        f\"{metrics_fp32.box.map:.4f}\",\n",
        "        f\"{speed_fp32:.2f}\",\n",
        "        f\"{loss_fp32[0]:.4f}\",\n",
        "        f\"{loss_fp32[1]:.4f}\"\n",
        "    ],\n",
        "    'INT8 (Quantized)': [\n",
        "        f\"{size_int8:.2f}\",\n",
        "        f\"{metrics_int8.box.map50:.4f}\",\n",
        "        f\"{metrics_int8.box.map:.4f}\",\n",
        "        f\"{speed_int8:.2f}\",\n",
        "        \"N/A (Inference Only)\",\n",
        "        \"N/A (Inference Only)\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"   QUANTIZATION PERFORMANCE REPORT   \")\n",
        "print(\"=\"*50)\n",
        "print(df.to_string(index=False))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- AUTOMATIC PASS/FAIL CHECK ---\n",
        "drop_map50 = metrics_fp32.box.map50 - metrics_int8.box.map50\n",
        "print(f\"\\nSize Reduction: {size_reduction:.2f}%\")\n",
        "print(f\"mAP@50 Drop:    {drop_map50:.4f}\")\n",
        "\n",
        "if drop_map50 > 0.05:\n",
        "    print(\"\\n❌ CRITICAL WARNING: High Accuracy Drop (>5%)\")\n",
        "    print(\"Recommendation: The dynamic quantization degraded the model too much.\")\n",
        "    print(\"Action: Attempt 'Static Quantization' with a calibration dataset or use QAT.\")\n",
        "else:\n",
        "    print(\"\\n✅ SUCCESS: Model is optimized and safe for FPGA deployment.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
