{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff5e112",
   "metadata": {},
   "source": [
    "# FINN model export + estimates\n",
    "\n",
    "This notebook builds a Brevitas INT8 model, optionally loads a checkpoint, exports QONNX, and provides placeholders for FINN estimate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ce88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import Int8ActPerTensorFixedPoint, Int8WeightPerTensorFixedPoint\n",
    "from brevitas.onnx import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from finn.util.visualization import showSrc , showInNetron\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import inspect\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b130ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_name = \"best_map.pth\"\n",
    "\n",
    "onnx_name = \"yolo_split_backbone.onnx\"\n",
    "onnx_finn_name = \"yolo_split_backbone.onnx\"\n",
    "build_dir = f\"/home/ug_lab/finn/trained_result\"\n",
    "\n",
    "export_path_onnx = f\"/home/ug_lab/finn/trained_result/{onnx_name}\"\n",
    "export_path_onnx_finn = f\"/home/ug_lab/finn/notebooks/pls11/{onnx_finn_name}\"\n",
    "pth_path = f\"/home/ug_lab/finn/trained_result/{pth_name}\"\n",
    "\n",
    "# folding_json = f\"/mnt/c/Users/bsuth/finn/notebooks/poz_train/custom_folding.json\"\n",
    "\n",
    "export_path_final_reports = f\"/home/ug_lab/finn/notebooks/pls11/final_output_reports/{onnx_name}_reports\"\n",
    "model_file = export_path_onnx_finn\n",
    "estimates_output = f\"{export_path_final_reports}/output_estimates\"\n",
    "estimates_output_dir = f\"{export_path_final_reports}/{onnx_name}_reports_v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97675722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "âœ… Model: Standard QuantConv2d (FINN-Ready)\n",
      "ðŸ“Š Total Parameters: 566,887\n",
      "ðŸš€ Status: UNDER LIMIT\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.nn import QuantConv2d, QuantReLU, QuantIdentity\n",
    "from brevitas.quant import Int8WeightPerTensorFloat as WeightQuant\n",
    "from brevitas.quant import Int8ActPerTensorFloat as ActQuant\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "\n",
    "# Optimized Quantizer for FINN Hardware\n",
    "class FinnWeightQuant(WeightQuant):\n",
    "    restrict_scaling_type = RestrictValueType.POWER_OF_TWO\n",
    "\n",
    "class FinnActQuant(ActQuant):\n",
    "    restrict_scaling_type = RestrictValueType.POWER_OF_TWO\n",
    "    signed = False\n",
    "    narrow_range = False\n",
    "    min_val = 0.0\n",
    "\n",
    "class TinyissimoYOLO_Standard(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # FINN expects QuantIdentity activations to be signed\n",
    "        self.input_quant = QuantIdentity(\n",
    "            act_quant=ActQuant,\n",
    "            return_quant_tensor=False,\n",
    "            signed=True,\n",
    "            narrow_range=False,\n",
    "        )\n",
    "\n",
    "        # Layer 1: Stem (1 -> 32)\n",
    "        self.conv1 = QuantConv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False, weight_quant=FinnWeightQuant)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.act1 = QuantReLU(\n",
    "            bit_width=8,\n",
    "            act_quant=FinnActQuant,\n",
    "            return_quant_tensor=False,\n",
    "            signed=False,\n",
    "            narrow_range=False,\n",
    "        )\n",
    "\n",
    "        # Main Body - Adjusted channels to fit < 600K\n",
    "        self.layer2 = self._make_layer(32, 64, stride=2)   # 18K\n",
    "        self.layer3 = self._make_layer(64, 112, stride=2)  # 64K (Reduced from 128)\n",
    "        self.layer4 = self._make_layer(112, 128, stride=2) # 129K\n",
    "        self.layer5 = self._make_layer(128, 144, stride=1) # 165K (Reduced from 160)\n",
    "        self.layer6 = self._make_layer(144, 144, stride=1) # 186K (Reduced from 160)\n",
    "\n",
    "        # Head: 144 -> 6 (Obj, x, y, w, h, Class)\n",
    "        self.final_conv = QuantConv2d(144, (5 + num_classes), kernel_size=1, bias=False, weight_quant=FinnWeightQuant)\n",
    "\n",
    "    def _make_layer(self, in_c, out_c, stride):\n",
    "        return nn.Sequential(\n",
    "            QuantConv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False, weight_quant=FinnWeightQuant),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            QuantReLU(\n",
    "                bit_width=4,\n",
    "                act_quant=FinnActQuant,\n",
    "                return_quant_tensor=False,\n",
    "                signed=False,\n",
    "                narrow_range=False,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_quant(x)\n",
    "        x = self.act1(self.bn1(self.conv1(x)))\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# --- 2. Instantiate & Patch ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TinyissimoYOLO_Standard(num_classes=1).to(device)\n",
    "\n",
    "def ultimate_patch(model):\n",
    "    for m in model.modules():\n",
    "        for attr in ['weight_quant_proxy', 'act_quant_proxy', 'input_quant_proxy', 'bias_quant_proxy']:\n",
    "            if hasattr(m, attr):\n",
    "                setattr(getattr(m, attr), 'requires_input_scale', False)\n",
    "\n",
    "ultimate_patch(model)\n",
    "\n",
    "# --- 3. Parameter Verification ---\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"âœ… Model: Standard QuantConv2d (FINN-Ready)\")\n",
    "print(f\"ðŸ“Š Total Parameters: {total_params:,}\")\n",
    "print(f\"ðŸš€ Status: {'UNDER LIMIT' if total_params < 600000 else 'OVER LIMIT'}\")\n",
    "print(f\"{'='*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6a6c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: /home/ug_lab/finn/trained_result/best_map.pth\n",
      "Saved QONNX to: /home/ug_lab/finn/trained_result/best_map_v2.onnx\n"
     ]
    }
   ],
   "source": [
    "model_name = TinyissimoYOLO_Standard\n",
    "CHECKPOINT_PATH = pth_path\n",
    "\n",
    "model = model_name()\n",
    "if CHECKPOINT_PATH and os.path.exists(CHECKPOINT_PATH):\n",
    "    state = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    print(f\"Loaded checkpoint: {CHECKPOINT_PATH}\")\n",
    "\n",
    "model.eval()\n",
    "model\n",
    "\n",
    "dummy_inp = torch.randn(1, 1, 128, 128)\n",
    "export_qonnx(model, dummy_inp, str(export_path_onnx))\n",
    "\n",
    "# if not export_path_onnx.exists():\n",
    "#     raise FileNotFoundError(f\"QONNX export failed, file not found at: {export_path_onnx}\")\n",
    "\n",
    "print(f\"Saved QONNX to: {export_path_onnx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875b8eb",
   "metadata": {},
   "source": [
    "All Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9edde4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Converted and saved FINN model: /home/ug_lab/finn/notebooks/pls11/best_map_finn_v2.onnx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "\n",
    "model = ModelWrapper(export_path_onnx)\n",
    "model = cleanup_model(model)\n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model = cleanup_model(model)\n",
    "\n",
    "# Convert QONNX quant nodes into FINN dialect first\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = cleanup_model(model)\n",
    "\n",
    "# Then apply FINN streamlining passes\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = cleanup_model(model)\n",
    "\n",
    "Path(export_path_onnx_finn).parent.mkdir(parents=True, exist_ok=True)\n",
    "model.save(export_path_onnx_finn)\n",
    "print(\"âœ… Converted and saved FINN model:\", export_path_onnx_finn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be2bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Checkpoint key match: 100.0%\n",
      "Inference done\n",
      "Input shape: (1, 1, 128, 128)\n",
      "Input sample (flattened): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 4.6136101e-05 3.0757405e-05 4.6136101e-05\n",
      " 7.6893506e-05 6.1514809e-05 1.2302962e-04 2.4605924e-04 4.1522493e-04\n",
      " 3.8446751e-04 1.2149174e-03 1.2302962e-04 3.0757405e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.6893506e-05 1.5378702e-05\n",
      " 1.8454441e-04 4.6136101e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 7.6893506e-05 6.1514809e-05 6.1514809e-05 1.5378702e-05 1.0765091e-04\n",
      " 3.0757405e-05 4.7673972e-04 1.3840831e-03 9.0734335e-04 1.9377163e-03\n",
      " 1.6916571e-04 1.0765091e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0765091e-04 4.6136101e-05 4.7673972e-04 9.2272203e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.4598232e-04 3.8446751e-04\n",
      " 7.6893506e-05 4.6136101e-05 1.5378701e-04 6.9204153e-04 1.7993080e-03\n",
      " 1.7685506e-03 1.6455210e-03 1.9684739e-03 1.8454441e-04 1.5378701e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.2272203e-05\n",
      " 4.6136101e-05 2.6143793e-04 1.0765091e-04 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.3060363e-04 5.6901196e-04 6.1514809e-05 6.1514809e-05\n",
      " 1.0611304e-03 3.3833142e-04 9.0734335e-04 9.3810074e-04 1.9223376e-03\n",
      " 2.1837757e-03 1.2302962e-04 7.6893506e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.0757405e-05 4.6136101e-05 2.1530181e-04\n",
      " 1.5378702e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.2302962e-04 1.6916571e-04 0.0000000e+00 6.1514809e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5378702e-05 1.5378702e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 6.1514809e-05 4.6136101e-05 4.6136101e-05 7.6893506e-05 3.8446751e-04\n",
      " 4.6136102e-04 7.6893506e-05 4.3060363e-04 1.2149174e-03 1.0149943e-03\n",
      " 2.6451366e-03 3.5986160e-03 3.3217994e-03 3.8600538e-03 9.3810074e-04\n",
      " 6.6128414e-04 4.3060363e-04 1.9992310e-04 1.2302962e-04 1.8454441e-04\n",
      " 4.6136101e-05 1.5378702e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 7.6893506e-05 6.7666284e-04 5.9976935e-04 4.6136101e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0757405e-05 0.0000000e+00\n",
      " 9.2272203e-05 4.6136101e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.5378702e-05 4.6136101e-05 4.6136101e-05 1.5378702e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0757405e-05 1.5378702e-05\n",
      " 1.5378702e-05 3.0757405e-05 6.1514805e-04 8.9196465e-04 9.2272203e-05\n",
      " 5.3825456e-04 1.5840061e-03 1.9684739e-03 3.7677817e-03 3.1680122e-03\n",
      " 3.1680122e-03 2.3990774e-03 1.2610535e-03 2.3068051e-04 1.2302962e-04\n",
      " 1.5378702e-05 0.0000000e+00 9.2272203e-05 1.5378702e-05 6.1514809e-05\n",
      " 0.0000000e+00 3.0757405e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.2272203e-05 1.6916571e-04\n",
      " 3.0757402e-04 6.1514809e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.0757405e-05 1.5378702e-05 1.5378702e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5378702e-05 4.6136101e-05\n",
      " 4.6136101e-05 1.5378702e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.0757405e-05 4.6136101e-05 0.0000000e+00\n",
      " 1.4917339e-03 2.4759709e-03 9.2272203e-05 6.9204153e-04 1.7070358e-03\n",
      " 2.7066513e-03 3.8600538e-03 3.3525568e-03 1.7070358e-03 1.1072665e-03\n",
      " 5.2287587e-04 1.3840832e-04 9.2272203e-05 4.6136101e-05 1.5378702e-05\n",
      " 4.6136101e-05 1.5378702e-05 6.1514809e-05 4.6136101e-05 4.6136101e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.6136101e-05 1.2302962e-04 6.6128414e-04 1.2302962e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0757405e-05\n",
      " 1.5378702e-05 3.0757405e-05 1.5378702e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.5378702e-05 1.5378702e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0765091e-04 1.3840832e-04 9.2272203e-05 2.3529413e-03 3.3217994e-03\n",
      " 5.2287587e-04 2.2299117e-03 2.0146100e-03 3.5063438e-03 2.9988466e-03\n",
      " 1.8146867e-03 2.7681663e-04 8.7658595e-04 7.6893506e-05 6.1514809e-05\n",
      " 1.5378702e-05 3.0757405e-05 3.0757405e-05 4.6136101e-05 3.0757405e-05\n",
      " 1.5378702e-05 1.3840832e-04 3.0757405e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0757405e-05\n",
      " 1.2302962e-04 1.0765091e-04 7.6893506e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Output shape: (1, 6, 8, 8)\n",
      "âœ… Saved verify input: /home/ug_lab/finn/notebooks/yolo_finn/input2.npy\n",
      "âœ… Saved verify output: /home/ug_lab/finn/notebooks/yolo_finn/output2.npy\n",
      "Output sample (flattened): [-8.366211  -7.3876953 -7.0341797 -7.2094727 -7.5737305 -7.650879\n",
      " -6.9140625 -8.234375  -7.6782227 -8.533203 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Import your Brevitas model definition\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create model\n",
    "model = TinyissimoYOLO_Standard().to(device)\n",
    "checkpoint = torch.load(pth_path, map_location=device)\n",
    "\n",
    "def _strip_prefixes(state_dict, prefixes):\n",
    "    out = {}\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = key\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for prefix in prefixes:\n",
    "                if new_key.startswith(prefix):\n",
    "                    new_key = new_key[len(prefix):]\n",
    "                    changed = True\n",
    "        out[new_key] = value\n",
    "    return out\n",
    "\n",
    "def _best_state_dict_for_model(raw_state, model_keys):\n",
    "    candidates = []\n",
    "    if isinstance(raw_state, dict):\n",
    "        candidates.append(raw_state)\n",
    "        candidates.append(_strip_prefixes(raw_state, [\"module.\"]))\n",
    "        candidates.append(_strip_prefixes(raw_state, [\"model.\"]))\n",
    "        candidates.append(_strip_prefixes(raw_state, [\"module.\", \"model.\", \"net.\"]))\n",
    "\n",
    "    best_sd = None\n",
    "    best_overlap = -1\n",
    "    for cand in candidates:\n",
    "        overlap = len(set(cand.keys()) & model_keys)\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_sd = cand\n",
    "    return best_sd, best_overlap\n",
    "\n",
    "# Support multiple checkpoint formats\n",
    "if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "    raw_state = checkpoint[\"model_state_dict\"]\n",
    "elif isinstance(checkpoint, dict) and \"state_dict\" in checkpoint:\n",
    "    raw_state = checkpoint[\"state_dict\"]\n",
    "else:\n",
    "    raw_state = checkpoint\n",
    "\n",
    "if not isinstance(raw_state, dict):\n",
    "    raise TypeError(\"Checkpoint does not contain a valid state_dict.\")\n",
    "\n",
    "model_keys = set(model.state_dict().keys())\n",
    "state_dict, overlap = _best_state_dict_for_model(raw_state, model_keys)\n",
    "match_ratio = overlap / max(1, len(model_keys))\n",
    "\n",
    "if match_ratio < 0.70:\n",
    "    raise RuntimeError(\n",
    "        f\"Checkpoint key match too low: {match_ratio:.1%}. \"\n",
    "        \"Likely wrong checkpoint format/model definition.\"\n",
    "    )\n",
    "\n",
    "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ… Checkpoint key match: {match_ratio:.1%}\")\n",
    "if missing_keys:\n",
    "    print(f\"âš ï¸ Missing keys: {len(missing_keys)}\")\n",
    "if unexpected_keys:\n",
    "    print(f\"âš ï¸ Unexpected keys: {len(unexpected_keys)}\")\n",
    "\n",
    "def preprocess_image(image_path, size=(128, 128)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    \n",
    "    img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # IMPORTANT: normalize to 0..1 for current quantizer setup\n",
    "    img = img.astype(np.float32)\n",
    "    \n",
    "    # Add batch + channel â†’ (1,1,128,128)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    tensor = torch.from_numpy(img).float()\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "\n",
    "image_path = \"/home/ug_lab/finn/notebooks/yolo_finn/Gao_ship_hh_02016082544040403.jpg\"\n",
    "\n",
    "input_tensor = preprocess_image(image_path)/255\n",
    "input_tensor = input_tensor.to(device)/255\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Move to numpy\n",
    "input_np = input_tensor.detach().cpu().numpy().astype(np.float32)\n",
    "output_np = output.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "# Save output (legacy file)\n",
    "np.save(\"output_from_pth.npy\", output_np)\n",
    "\n",
    "# Save FINN verification files\n",
    "verify_dir = \"/home/ug_lab/finn/notebooks/yolo_finn\"\n",
    "os.makedirs(verify_dir, exist_ok=True)\n",
    "verify_input_path = os.path.join(verify_dir, \"input2.npy\")\n",
    "verify_output_path = os.path.join(verify_dir, \"output2.npy\")\n",
    "np.save(verify_input_path, input_np)\n",
    "np.save(verify_output_path, output_np)\n",
    "\n",
    "print(\"Inference done\")\n",
    "print(\"Input shape:\", input_np.shape)\n",
    "print(\"Input sample (flattened):\", input_np.flatten()[:1000])\n",
    "\n",
    "print(\"Output shape:\", output_np.shape)\n",
    "print(f\"âœ… Saved verify input: {verify_input_path}\")\n",
    "print(f\"âœ… Saved verify output: {verify_output_path}\")\n",
    "print(\"Output sample (flattened):\", output_np.flatten()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4500a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global input name: global_in\n",
      "Preproc export input shape: (1, 1, 128, 128)\n",
      "âœ… Merged preproc and saved: /home/ug_lab/finn/notebooks/pls11/best_map_finn_v2.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ug_lab/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor, NormalizePreProc\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from brevitas.onnx import export_qonnx\n",
    "\n",
    "# Load FINN ONNX model wrapper explicitly (do not reuse torch model variable)\n",
    "finn_model = ModelWrapper(export_path_onnx_finn)\n",
    "global_inp_name = finn_model.graph.input[0].name\n",
    "print(\"Global input name:\", global_inp_name)\n",
    "ishape = torch.randn(1, 1, 128, 128)\n",
    "\n",
    "print(f\"Preproc export input shape: {tuple(ishape.shape)}\")\n",
    "\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "\n",
    "chkpt_preproc_name = build_dir + \"/best_map.onnx\"\n",
    "export_qonnx(totensor_pyt, ishape, chkpt_preproc_name)\n",
    "\n",
    "# join preprocessing and core model\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "finn_model = finn_model.transform(MergeONNXModels(pre_model))\n",
    "\n",
    "# add input quantization annotation: UINT8 for BNN-PYNQ models\n",
    "global_inp_name = finn_model.graph.input[0].name\n",
    "finn_model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "finn_model.save(export_path_onnx_finn)\n",
    "print(\"âœ… Merged preproc and saved:\", export_path_onnx_finn)\n",
    "\n",
    "# showInNetron(export_path_onnx_finn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146d62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FINN-ready model saved.\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import (\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    RemoveStaticGraphInputs,\n",
    ")\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from finn.transformation.streamline.absorb import (\n",
    "    AbsorbAddIntoMultiThreshold,\n",
    "    AbsorbMulIntoMultiThreshold,\n",
    ")\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveMulPastMaxPool,\n",
    "    MoveAddPastMul,\n",
    ")\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "# Always load ONNX as ModelWrapper here (avoid torch model shadowing)\n",
    "model = ModelWrapper(export_path_onnx_finn)\n",
    "model = cleanup_model(model)\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model = cleanup_model(model)\n",
    "\n",
    "# Convert only if still in QONNX dialect\n",
    "try:\n",
    "    model = model.transform(ConvertQONNXtoFINN())\n",
    "    model = cleanup_model(model)\n",
    "except Exception as e:\n",
    "    print(\"ConvertQONNXtoFINN skipped/failed (possibly already FINN dialect):\", type(e).__name__)\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(MoveMulPastMaxPool())\n",
    "model = model.transform(MoveAddPastMul())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "model = model.transform(InferDataTypes())\n",
    "\n",
    "model.save(export_path_onnx_finn)\n",
    "print(\"âœ… FINN-ready model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete previous run results if they exist.\n",
    "if os.path.exists(estimates_output):\n",
    "    shutil.rmtree(estimates_output )\n",
    "    print(\"Previous run results deleted.\")\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    raise FileNotFoundError(f\"Model file not found: {model_file}\")\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir = estimates_output,\n",
    "    # mvau_wwidth_max = 120,\n",
    "    synth_clk_period_ns = 50.0,\n",
    "    split_large_fifos=True,\n",
    "    target_fps=60,   # LOWER\n",
    "    # folding_config_file = folding_json,\n",
    "    auto_fifo_depths=True,\n",
    "    fpga_part = \"xc7z020clg400-1\",\n",
    "    board = \"Pynq-Z2\",\n",
    "    steps = build_cfg.default_build_dataflow_steps,\n",
    "    # verify_steps = [build_cfg.VerificationStepType.QONNX_TO_FINN_PYTHON,\n",
    "    #                 # build_cfg.VerificationStepType.STREAMLINED_PYTHON,\n",
    "    #                 # build_cfg.VerificationStepType.TIDY_UP_PYTHON,\n",
    "    #                 build_cfg.VerificationStepType.FOLDED_HLS_CPPSIM,\n",
    "    #                 build_cfg.VerificationStepType.STITCHED_IP_RTLSIM],\n",
    "    # verify_input_npy = \"/home/ug_lab/finn/notebooks/yolo_finn/input2.npy\",\n",
    "    # verify_expected_output_npy = \"/home/ug_lab/finn/notebooks/yolo_finn/output2.npy\",\n",
    "    # verify_save_full_context = True,  \n",
    "    \n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE\n",
    "        # build_cfg.DataflowOutputType.BITFILE,\n",
    "        # build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        # build_cfg.DataflowOutputType.OOC_SYNTH,   \n",
    "    ]\n",
    ")\n",
    "\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)\n",
    "\n",
    "! cat {estimates_output}/report/estimate_network_performance.json\n",
    "\n",
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret\n",
    "\n",
    "read_json_dict(estimates_output + \"/report/estimate_layer_cycles.json\")\n",
    "read_json_dict(estimates_output + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b3a4b",
   "metadata": {},
   "source": [
    "estimates report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3858c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LUT_used': 26722.0, 'LUT_pct': 50.22932330827068, 'FF_used': 0.0, 'FF_pct': 0.0, 'BRAM36_used': 157.0, 'BRAM36_pct': 112.14285714285714, 'DSP_used': 1.0, 'DSP_pct': 0.45454545454545453}\n"
     ]
    }
   ],
   "source": [
    "res = read_json_dict(estimates_output + \"/report/estimate_layer_resources.json\")\n",
    "tot = res.get(\"total\", {})\n",
    "\n",
    "# XC7Z020 (PYNQ-Z2) resource totals from ds187.\n",
    "TOTAL_LUT = 53200\n",
    "TOTAL_FF = 106400\n",
    "TOTAL_BRAM36 = 140\n",
    "TOTAL_DSP = 220\n",
    "\n",
    "# FINN reports BRAM_18K; convert to BRAM36K blocks.\n",
    "bram18 = float(tot.get(\"BRAM_18K\", 0))\n",
    "bram36 = bram18 / 2.0\n",
    "lut = float(tot.get(\"LUT\", 0))\n",
    "dsp = float(tot.get(\"DSP\", 0))\n",
    "ff = float(tot.get(\"FF\", tot.get(\"REG\", tot.get(\"Register\", 0))))\n",
    "\n",
    "def pct(used, total):\n",
    "    return 0.0 if total == 0 else (used / total) * 100.0\n",
    "\n",
    "util = {\n",
    "    \"LUT_used\": lut,\n",
    "    \"LUT_pct\": pct(lut, TOTAL_LUT),\n",
    "    \"FF_used\": ff,\n",
    "    \"FF_pct\": pct(ff, TOTAL_FF),\n",
    "    \"BRAM36_used\": bram36,\n",
    "    \"BRAM36_pct\": pct(bram36, TOTAL_BRAM36),\n",
    "    \"DSP_used\": dsp,\n",
    "    \"DSP_pct\": pct(dsp, TOTAL_DSP),\n",
    "}\n",
    "\n",
    "print(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.onnx_exec import execute_onnx\n",
    "from qonnx.core.datatype import DataType\n",
    "import time\n",
    "\n",
    "model_path = \"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/best.finn.onnx_finn.onnx\"\n",
    "model = ModelWrapper(model_path)\n",
    "\n",
    "# First input\n",
    "inp_name = model.graph.input[0].name\n",
    "inp_shape = model.get_tensor_shape(inp_name)\n",
    "inp_dt = model.get_tensor_datatype(inp_name) or DataType.FLOAT32\n",
    "\n",
    "def _np_dtype(dt):\n",
    "    if hasattr(dt, \"numpy\"):\n",
    "        return dt.numpy()\n",
    "    dt_str = str(dt).lower()\n",
    "    if \"float16\" in dt_str:\n",
    "        return np.float16\n",
    "    if \"float\" in dt_str:\n",
    "        return np.float32\n",
    "    if \"uint8\" in dt_str:\n",
    "        return np.uint8\n",
    "    if \"int8\" in dt_str:\n",
    "        return np.int8\n",
    "    if \"uint16\" in dt_str:\n",
    "        return np.uint16\n",
    "    if \"int16\" in dt_str:\n",
    "        return np.int16\n",
    "    if \"uint32\" in dt_str:\n",
    "        return np.uint32\n",
    "    if \"int32\" in dt_str:\n",
    "        return np.int32\n",
    "    if \"uint64\" in dt_str:\n",
    "        return np.uint64\n",
    "    if \"int64\" in dt_str:\n",
    "        return np.int64\n",
    "    return np.float32\n",
    "\n",
    "def _is_integer(dt, np_dt):\n",
    "    if hasattr(dt, \"is_integer\"):\n",
    "        return dt.is_integer()\n",
    "    return np.issubdtype(np_dt, np.integer)\n",
    "\n",
    "def _int_range(dt, np_dt):\n",
    "    if hasattr(dt, \"min\") and hasattr(dt, \"max\"):\n",
    "        return dt.min(), dt.max()\n",
    "    info = np.iinfo(np_dt)\n",
    "    return info.min, info.max\n",
    "\n",
    "np_dt = _np_dtype(inp_dt)\n",
    "\n",
    "# Random input matching dtype/range\n",
    "if _is_integer(inp_dt, np_dt):\n",
    "    lo, hi = _int_range(inp_dt, np_dt)\n",
    "    x = np.random.randint(lo, hi + 1, size=inp_shape, dtype=np_dt)\n",
    "else:\n",
    "    x = np.random.randn(*inp_shape).astype(np_dt)\n",
    "\n",
    "np.save(\"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/input.npy\", x)\n",
    "\n",
    "# Run\n",
    "start_time = time.time()\n",
    "\n",
    "outputs = execute_onnx(model, {inp_name: x})\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "out0 = next(iter(outputs.values()))\n",
    "np.save(\"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/output.npy\", out0)\n",
    "\n",
    "for name, val in outputs.items():\n",
    "    print(name, val.shape)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cc88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input shape: [1, 3, 416, 416] dtype: FLOAT32\n",
      "model output shape: [1, 18, 13, 13]\n",
      "input.npy shape: (1, 3, 416, 416) dtype: float32\n",
      "output.npy shape: (1, 18, 13, 13) dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(\"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/best.finn.onnx_finn.onnx\")\n",
    "inp_name = model.graph.input[0].name\n",
    "out_name = model.graph.output[0].name\n",
    "inp_shape = model.get_tensor_shape(inp_name)\n",
    "out_shape = model.get_tensor_shape(out_name)\n",
    "inp_dt = model.get_tensor_datatype(inp_name) or DataType.FLOAT32\n",
    "\n",
    "x = np.load(\"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/input.npy\")\n",
    "y = np.load(\"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/output.npy\")\n",
    "\n",
    "print(\"model input shape:\", inp_shape, \"dtype:\", inp_dt)\n",
    "print(\"model output shape:\", out_shape)\n",
    "print(\"input.npy shape:\", x.shape, \"dtype:\", x.dtype)\n",
    "print(\"output.npy shape:\", y.shape, \"dtype:\", y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ef0b3",
   "metadata": {},
   "source": [
    "## Verification debug summary\n",
    "\n",
    "This cell summarizes PASS/FAIL and compares FAIL outputs against expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verification_output: /mnt/c/Users/bsuth/finn/notebooks/yolo_finn/final_output_reports/best.finn.onnx_reports/output_estimates/verification_output\n",
      "PASS files: 0\n",
      "FAIL files: 2\n",
      "latest FAIL: verify_stitched_ip_rtlsim_0_FAIL.npz\n",
      "using FAIL: verify_stitched_ip_rtlsim_0_FAIL.npz\n",
      "keys: ['global_in', 'global_out', 'Mul_0_param0', 'Transpose_1_out0', 'MultiThreshold_0_param0', 'MatMul_0_param0', 'Transpose_0_out0', 'Im2Col_0_out0', 'MatMul_0_out0', 'MultiThreshold_0_out0', 'MultiThreshold_9_out0', 'GenericPartition_0_global_in', 'GenericPartition_0_MVAU_hls_0_param1', 'GenericPartition_0_MVAU_hls_1_param1', 'GenericPartition_0_MVAU_hls_2_param1', 'GenericPartition_0_MVAU_hls_3_param1', 'GenericPartition_0_MVAU_hls_4_param1', 'GenericPartition_0_MVAU_hls_5_param1', 'GenericPartition_0_MVAU_hls_6_param1', 'GenericPartition_0_MVAU_hls_7_param1', 'GenericPartition_0_MVAU_hls_8_param1', 'GenericPartition_0_MVAU_hls_0_param0', 'GenericPartition_0_MVAU_hls_1_param0', 'GenericPartition_0_MVAU_hls_2_param0', 'GenericPartition_0_MVAU_hls_3_param0', 'GenericPartition_0_MVAU_hls_4_param0', 'GenericPartition_0_MVAU_hls_5_param0', 'GenericPartition_0_MVAU_hls_6_param0', 'GenericPartition_0_MVAU_hls_7_param0', 'GenericPartition_0_MVAU_hls_8_param0', 'GenericPartition_0_StreamingMaxPool_hls_0_out0', 'GenericPartition_0_StreamingMaxPool_hls_1_out0', 'GenericPartition_0_StreamingMaxPool_hls_2_out0', 'GenericPartition_0_StreamingMaxPool_hls_3_out0', 'GenericPartition_0_StreamingMaxPool_hls_4_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_0_out0', 'GenericPartition_0_MVAU_hls_0_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_1_out0', 'GenericPartition_0_MVAU_hls_1_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_2_out0', 'GenericPartition_0_MVAU_hls_2_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_3_out0', 'GenericPartition_0_MVAU_hls_3_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_4_out0', 'GenericPartition_0_MVAU_hls_4_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_5_out0', 'GenericPartition_0_MVAU_hls_5_out0', 'GenericPartition_0_MVAU_hls_6_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_6_out0', 'GenericPartition_0_MVAU_hls_7_out0', 'GenericPartition_0_ConvolutionInputGenerator_rtl_7_out0', 'GenericPartition_0_FMPadding_rtl_0_out0', 'GenericPartition_0_FMPadding_rtl_1_out0', 'GenericPartition_0_FMPadding_rtl_2_out0', 'GenericPartition_0_FMPadding_rtl_3_out0', 'GenericPartition_0_FMPadding_rtl_4_out0', 'GenericPartition_0_FMPadding_rtl_5_out0', 'GenericPartition_0_FMPadding_rtl_6_out0', 'GenericPartition_0_FMPadding_rtl_7_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_0_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_1_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_2_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_3_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_4_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_5_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_6_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_7_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_8_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_9_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_10_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_11_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_12_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_13_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_14_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_15_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_16_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_17_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_18_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_19_out0', 'GenericPartition_0_StreamingDataWidthConverter_rtl_20_out0', 'GenericPartition_0_StreamingFIFO_rtl_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_2_out0', 'GenericPartition_0_StreamingFIFO_rtl_3_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_4_out0', 'GenericPartition_0_StreamingFIFO_rtl_5_out0', 'GenericPartition_0_StreamingFIFO_rtl_6_out0', 'GenericPartition_0_StreamingFIFO_rtl_7_out0', 'GenericPartition_0_StreamingFIFO_rtl_8_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_9_out0', 'GenericPartition_0_StreamingFIFO_rtl_10_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_11_out0', 'GenericPartition_0_StreamingFIFO_rtl_12_out0', 'GenericPartition_0_StreamingFIFO_rtl_13_out0', 'GenericPartition_0_StreamingFIFO_rtl_14_out0', 'GenericPartition_0_StreamingFIFO_rtl_15_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_16_out0', 'GenericPartition_0_StreamingFIFO_rtl_17_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_18_out0', 'GenericPartition_0_StreamingFIFO_rtl_19_out0', 'GenericPartition_0_StreamingFIFO_rtl_20_out0', 'GenericPartition_0_StreamingFIFO_rtl_21_out0', 'GenericPartition_0_StreamingFIFO_rtl_22_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_23_out0', 'GenericPartition_0_StreamingFIFO_rtl_24_out0', 'GenericPartition_0_StreamingFIFO_rtl_25_out0', 'GenericPartition_0_StreamingFIFO_rtl_26_out0', 'GenericPartition_0_StreamingFIFO_rtl_27_out0', 'GenericPartition_0_StreamingFIFO_rtl_28_out0', 'GenericPartition_0_StreamingFIFO_rtl_29_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_30_out0', 'GenericPartition_0_StreamingFIFO_rtl_31_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_32_out0', 'GenericPartition_0_StreamingFIFO_rtl_33_out0', 'GenericPartition_0_StreamingFIFO_rtl_34_out0', 'GenericPartition_0_StreamingFIFO_rtl_35_2_out0', 'GenericPartition_0_StreamingFIFO_rtl_36_out0', 'GenericPartition_0_StreamingFIFO_rtl_37_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_38_out0', 'GenericPartition_0_StreamingFIFO_rtl_39_out0', 'GenericPartition_0_StreamingFIFO_rtl_40_out0', 'GenericPartition_0_StreamingFIFO_rtl_41_out0', 'GenericPartition_0_StreamingFIFO_rtl_42_2_out0', 'GenericPartition_0_StreamingFIFO_rtl_43_out0', 'GenericPartition_0_StreamingFIFO_rtl_44_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_45_out0', 'GenericPartition_0_StreamingFIFO_rtl_46_out0', 'GenericPartition_0_StreamingFIFO_rtl_47_out0', 'GenericPartition_0_StreamingFIFO_rtl_48_2_out0', 'GenericPartition_0_StreamingFIFO_rtl_49_out0', 'GenericPartition_0_StreamingFIFO_rtl_50_2_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_6_out0', 'GenericPartition_0_MVAU_hls_8_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_2_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_3_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_4_out0', 'GenericPartition_0_StreamingFIFO_rtl_0_5_out0', 'GenericPartition_0_StreamingFIFO_rtl_3_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_8_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_10_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_15_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_17_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_22_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_29_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_31_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_35_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_35_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_37_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_42_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_42_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_44_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_48_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_48_1_out0', 'GenericPartition_0_StreamingFIFO_rtl_50_0_out0', 'GenericPartition_0_StreamingFIFO_rtl_50_1_out0']\n",
      "expected output: [[[[ 0.04724409  0.11023622  0.03937008 ... -0.05511811  0.03937008 -0.05511811]\n",
      "   [ 0.03149606  0.03937008 -0.12598425 ... -0.01574803 -0.08661418 -0.11023622]\n",
      "   [ 0.05511811 -0.03149606 -0.14173228 ... -0.05511811 -0.13385826 -0.03149606]\n",
      "   ...\n",
      "   [ 0.18110237 -0.03937008 -0.05511811 ... -0.22834645 -0.14173228  0.11811024]\n",
      "   [ 0.13385826  0.12598425 -0.1496063  ... -0.05511811 -0.00787402 -0.06299213]\n",
      "   [ 0.07874016 -0.03149606  0.03149606 ...  0.03937008  0.03937008  0.        ]]\n",
      "\n",
      "  [[ 0.1496063   0.07874016  0.         ...  0.3464567   0.2992126   0.1496063 ]\n",
      "   [ 0.03149606 -0.00787402 -0.02362205 ...  0.03149606  0.         -0.33858266]\n",
      "   [ 0.07874016  0.22834645  0.4566929  ... -0.15748031 -0.06299213  0.01574803]\n",
      "   ...\n",
      "   [-0.02362205 -0.03149606 -0.04724409 ...  0.32283464  0.42519686  0.46456692]\n",
      "   [-0.21259843 -0.21259843 -0.11023622 ...  0.07874016  0.1023622   0.21259843]\n",
      "   [-0.2047244  -0.3464567  -0.48031497 ... -0.31496063 -0.33858266 -0.36220473]]\n",
      "\n",
      "  [[ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.21259843 -0.22047244 -0.22834645 ... -0.27559054 -0.27559054 -0.32283464]\n",
      "   [-0.15748031  0.02362205  0.01574803 ... -0.07086614 -0.08661418 -0.06299213]\n",
      "   [-0.08661418 -0.07874016 -0.1023622  ... -0.07086614 -0.01574803  0.09448819]\n",
      "   ...\n",
      "   [-0.18897638 -0.11023622 -0.09448819 ...  0.03149606  0.11023622  0.08661418]\n",
      "   [-0.1023622  -0.13385826 -0.1496063  ... -0.1023622  -0.15748031 -0.22047244]\n",
      "   [-0.06299213 -0.07086614 -0.04724409 ... -0.1023622  -0.26771653 -0.12598425]]\n",
      "\n",
      "  [[-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   ...\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]]\n",
      "\n",
      "  [[-0.00787402 -0.01574803 -0.02362205 ... -0.01574803 -0.01574803 -0.00787402]\n",
      "   [-0.00787402 -0.02362205 -0.02362205 ... -0.02362205 -0.02362205 -0.01574803]\n",
      "   [-0.01574803 -0.03149606 -0.03149606 ... -0.03149606 -0.03937008 -0.02362205]\n",
      "   ...\n",
      "   [-0.01574803 -0.03937008 -0.04724409 ... -0.03937008 -0.03149606 -0.01574803]\n",
      "   [-0.01574803 -0.03149606 -0.03149606 ... -0.03149606 -0.03149606 -0.02362205]\n",
      "   [-0.01574803 -0.03149606 -0.03149606 ... -0.03149606 -0.03937008 -0.03149606]]]]\n",
      "global_out: [[[[ 0.07086614  0.01574803  0.01574803 ...  0.01574803  0.11023622  0.14173228]\n",
      "   [-0.12598425 -0.07874016  0.04724409 ... -0.03149606  0.06299213  0.31496063]\n",
      "   [-0.03149606 -0.02362205  0.03937008 ...  0.06299213  0.07086614  0.2519685 ]\n",
      "   ...\n",
      "   [-0.08661418  0.11023622  0.1496063  ...  0.03937008  0.04724409  0.21259843]\n",
      "   [-0.11023622  0.11023622  0.12598425 ...  0.08661418  0.03937008  0.11023622]\n",
      "   [-0.00787402  0.1023622   0.13385826 ...  0.09448819  0.16535433  0.03149606]]\n",
      "\n",
      "  [[-0.12598425 -0.18110237 -0.14173228 ... -0.11811024 -0.13385826 -0.18897638]\n",
      "   [-0.1496063  -0.01574803  0.00787402 ...  0.06299213  0.00787402 -0.01574803]\n",
      "   [ 0.09448819  0.25984251  0.2992126  ...  0.09448819  0.16535433  0.2519685 ]\n",
      "   ...\n",
      "   [ 0.09448819  0.21259843  0.24409449 ...  0.2992126   0.22834645  0.13385826]\n",
      "   [ 0.2992126   0.3464567   0.42519686 ...  0.46456692  0.52755904  0.07086614]\n",
      "   [ 0.33070865  0.26771653  0.25984251 ...  0.24409449  0.2913386   0.22834645]]\n",
      "\n",
      "  [[ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          0.8582677 ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]\n",
      "   [ 1.          1.          1.         ...  1.          1.          1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00787402 -0.03149606 -0.00787402 ... -0.04724409 -0.07874016 -0.11023622]\n",
      "   [ 0.2913386   0.33070865  0.37007874 ...  0.2913386   0.31496063  0.23622048]\n",
      "   [ 0.503937    0.511811    0.503937   ...  0.46456692  0.4015748   0.26771653]\n",
      "   ...\n",
      "   [ 0.37007874  0.503937    0.51968503 ...  0.30708662  0.25984251  0.12598425]\n",
      "   [ 0.33070865  0.35433072  0.42519686 ...  0.17322835  0.16535433  0.03149606]\n",
      "   [-0.08661418 -0.1023622  -0.1023622  ... -0.17322835 -0.15748031 -0.15748031]]\n",
      "\n",
      "  [[-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   ...\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]\n",
      "   [-1.         -1.         -1.         ... -1.         -1.         -1.        ]]\n",
      "\n",
      "  [[ 0.          0.         -0.01574803 ...  0.         -0.01574803  0.00787402]\n",
      "   [-0.01574803 -0.01574803 -0.01574803 ... -0.00787402 -0.00787402  0.01574803]\n",
      "   [-0.00787402 -0.00787402 -0.01574803 ... -0.02362205 -0.00787402  0.01574803]\n",
      "   ...\n",
      "   [-0.00787402 -0.00787402 -0.00787402 ... -0.01574803 -0.02362205  0.00787402]\n",
      "   [ 0.          0.          0.         ...  0.00787402  0.          0.02362205]\n",
      "   [-0.01574803 -0.02362205 -0.02362205 ... -0.00787402 -0.01574803 -0.00787402]]]]\n",
      "output key: global_out\n",
      "max abs diff: 1.039370059967041\n",
      "mean abs diff: 0.12179356813430786\n",
      "worst idx: (0, 8, 9, 12) expected: 1.0 actual: -0.03937008\n",
      "global_in vs input.npy max abs diff: 0.0\n",
      "global_in vs input.npy mean abs diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "base_reports_dir = \"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/final_output_reports\"\n",
    "ver_dir = f\"{base_reports_dir}/{onnx_name}_reports/output_estimates/verification_output\"\n",
    "expected_path = \"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/output.npy\"\n",
    "input_path = \"/mnt/c/Users/bsuth/finn/notebooks/yolo_finn/input.npy\"\n",
    "\n",
    "if not os.path.isdir(ver_dir):\n",
    "    raise FileNotFoundError(f\"verification_output not found: {ver_dir}\")\n",
    "\n",
    "npz_files = sorted(\n",
    "    [os.path.join(ver_dir, f) for f in os.listdir(ver_dir) if f.endswith(\".npz\")],\n",
    "    key=lambda p: os.path.getmtime(p),\n",
    ")\n",
    "pass_files = [p for p in npz_files if \"_PASS\" in os.path.basename(p)]\n",
    "fail_files = [p for p in npz_files if \"_FAIL\" in os.path.basename(p)]\n",
    "\n",
    "print(\"verification_output:\", ver_dir)\n",
    "print(\"PASS files:\", len(pass_files))\n",
    "print(\"FAIL files:\", len(fail_files))\n",
    "if pass_files:\n",
    "    print(\"latest PASS:\", os.path.basename(pass_files[-1]))\n",
    "if fail_files:\n",
    "    print(\"latest FAIL:\", os.path.basename(fail_files[-1]))\n",
    "\n",
    "if not fail_files:\n",
    "    print(\"No FAIL files found.\")\n",
    "else:\n",
    "    fail_path = fail_files[-1]\n",
    "    data = np.load(fail_path)\n",
    "    print(\"using FAIL:\", os.path.basename(fail_path))\n",
    "    print(\"keys:\", list(data.keys()))\n",
    "\n",
    "    np.set_printoptions(threshold=200, edgeitems=3, linewidth=120)\n",
    "    exp = np.load(expected_path)\n",
    "    print(\"expected output:\", exp)\n",
    "\n",
    "    if \"global_out\" in data:\n",
    "        print(\"global_out:\", data[\"global_out\"])\n",
    "    else:\n",
    "        match_keys = [k for k in data.keys() if data[k].shape == exp.shape]\n",
    "        if match_keys:\n",
    "            out_key = match_keys[0]\n",
    "            print(\"global_out (matched by shape):\", data[out_key])\n",
    "        else:\n",
    "            print(\"global_out not found and no matching shape.\")\n",
    "\n",
    "    match_keys = [k for k in data.keys() if data[k].shape == exp.shape]\n",
    "    if not match_keys:\n",
    "        print(\"No tensor matches expected output shape.\")\n",
    "    else:\n",
    "        out_key = match_keys[0]\n",
    "        out = data[out_key]\n",
    "        diff = np.abs(exp - out)\n",
    "        print(\"output key:\", out_key)\n",
    "        print(\"max abs diff:\", float(diff.max()))\n",
    "        print(\"mean abs diff:\", float(diff.mean()))\n",
    "        idx = np.unravel_index(np.argmax(diff), diff.shape)\n",
    "        print(\"worst idx:\", idx, \"expected:\", exp[idx], \"actual:\", out[idx])\n",
    "\n",
    "    if \"global_in\" in data and os.path.exists(input_path):\n",
    "        ver_in = data[\"global_in\"]\n",
    "        inp = np.load(input_path)\n",
    "        if ver_in.shape != inp.shape:\n",
    "            print(\"global_in shape differs from input.npy\")\n",
    "            print(\"global_in:\", ver_in.shape, \"input.npy:\", inp.shape)\n",
    "        else:\n",
    "            in_diff = np.abs(ver_in - inp)\n",
    "            print(\"global_in vs input.npy max abs diff:\", float(in_diff.max()))\n",
    "            print(\"global_in vs input.npy mean abs diff:\", float(in_diff.mean()))\n",
    "    else:\n",
    "        print(\"global_in not found in npz or input.npy missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc7f34",
   "metadata": {},
   "source": [
    "FLOW FOR GENERATING THE HLS CODES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fe4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Delete previous run results if they exist.\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted.\")\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    raise FileNotFoundError(f\"Model file not found: {model_file}\")\n",
    "\n",
    "# Build config kwargs, filtered to what this FINN version accepts.\n",
    "# cfg_kwargs = {\n",
    "#     \"output_dir\": estimates_output_dir,\n",
    "#     \"mvau_wwidth_max\": 80,\n",
    "#     \"target_fps\": 3000,\n",
    "#     \"synth_clk_period_ns\": 10,\n",
    "#     \"fpga_part\": \"xc7z020clg400-1\",\n",
    "#     \"board\": \"Pynq-Z2\",\n",
    "#     \"shell_flow_type\": build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "#     \"steps\": build_cfg.default_build_dataflow_steps,\n",
    "#     \"generate_outputs\":[\n",
    "#         build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "#         build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "#         build_cfg.DataflowOutputType.BITFILE,\n",
    "#         build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "#         build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "#         build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "#         build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE\n",
    "#         build_cfg.DataflowOutputType.\n",
    "#     ]\n",
    "#     # \"steps\": build_cfg.estimate_only_dataflow_steps \n",
    "# # }\n",
    "\n",
    "# sig = inspect.signature(build_cfg.DataflowBuildConfig)\n",
    "# print(f\"DataflowBuildConfig parameters: {sig.parameters.keys()}\")\n",
    "# filtered_kwargs = {k: v for k, v in cfg_kwargs.items() if k in sig.parameters}\n",
    "\n",
    "# # Prefer estimate reports output type if available, else use string token.\n",
    "# if \"generate_outputs\" in sig.parameters:\n",
    "#     output_type = getattr(build_cfg, \"DataflowOutputType\", None)\n",
    "#     if output_type is not None and hasattr(output_type, \"ESTIMATE_REPORTS\"):\n",
    "#         filtered_kwargs[\"generate_outputs\"] = [output_type.ESTIMATE_REPORTS]\n",
    "#     else:\n",
    "#         filtered_kwargs[\"generate_outputs\"] = [\"estimate\"]\n",
    "\n",
    "# cfg = build_cfg.DataflowBuildConfig(**filtered_kwargs)\n",
    "\n",
    "# def resolve_build_fn():\n",
    "#     try:\n",
    "#         from finn.builder.build_dataflow import build_dataflow as direct_build_dataflow\n",
    "#         return direct_build_dataflow\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     candidates = [\"build_dataflow\", \"build_dataflow_cfg\", \"build_dataflow_app\"]\n",
    "#     for name in candidates:\n",
    "#         fn = getattr(build, name, None)\n",
    "#         if callable(fn):\n",
    "#             return fn\n",
    "#     for name in candidates:\n",
    "#         fn = getattr(build_cfg, name, None)\n",
    "#         if callable(fn):\n",
    "#             return fn\n",
    "#     return None\n",
    "\n",
    "# # Run FINN build to generate analytic + HLS estimates.\n",
    "# build_fn = resolve_build_fn()\n",
    "# if build_fn is None:\n",
    "#     available = [name for name, obj in inspect.getmembers(build) if callable(obj)]\n",
    "#     raise AttributeError(\n",
    "#         \"No build_dataflow function found in this FINN version. \"\n",
    "#         f\"Callable names in finn.builder.build_dataflow: {available}\"\n",
    "# )\n",
    "# build_fn(model_file, cfg)\n",
    "\n",
    "# print(f\"Reports are in: {estimates_output_dir}/reports\")\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output,\n",
    "    mvau_wwidth_max = 36,\n",
    "    synth_clk_period_ns = 20.0,\n",
    "    split_large_fifos=True,\n",
    "    target_fps=1000,   # LOWER\n",
    "    folding_config_file = folding_json,\n",
    "    auto_fifo_depths=False,   \n",
    "    fpga_part           = \"xc7z020clg400-1\",\n",
    "    board = \"Pynq-Z2\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.graph.node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd814d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"/mnt/c/Users/bsuth/finn/notebooks/poz_train/dataset/Dataset_for_SAR_images/images/Gao_ship_hh_02016082544040403.jpg\"\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image = image.resize((128, 128))\n",
    "w, h = image.size\n",
    "image = T.ToTensor()(image)\n",
    "print(image.shape, image.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
